{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Импорт библиотеки, загрузка моделей и словаря wordnet\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'way',\n",
       " 'to',\n",
       " 'get',\n",
       " 'started',\n",
       " 'is',\n",
       " 'to',\n",
       " 'quit',\n",
       " 'talking',\n",
       " 'and',\n",
       " 'begin',\n",
       " 'doing']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Токенизация текста\n",
    "text = 'The way to get started is to quit talking and begin doing'\n",
    "tokenized = nltk.word_tokenize(text)\n",
    "tokenized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('way', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('get', 'VB'),\n",
       " ('started', 'VBN'),\n",
       " ('is', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('quit', 'VB'),\n",
       " ('talking', 'VBG'),\n",
       " ('and', 'CC'),\n",
       " ('begin', 'VB'),\n",
       " ('doing', 'VBG')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# разбор по частям речи\n",
    "tagged = nltk.pos_tag(tokenized)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VB'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged[3][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'way',\n",
       " 'to',\n",
       " 'get',\n",
       " 'started',\n",
       " 'is',\n",
       " 'to',\n",
       " 'quit',\n",
       " 'talking',\n",
       " 'and',\n",
       " 'begin',\n",
       " 'doing']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# лемматизация\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemm = WordNetLemmatizer()\n",
    "lemmatized = [lemm.lemmatize(word) for word in tokenized]\n",
    "lemmatized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', None),\n",
       " ('way', 'n'),\n",
       " ('to', None),\n",
       " ('get', 'v'),\n",
       " ('started', 'v'),\n",
       " ('is', 'v'),\n",
       " ('to', None),\n",
       " ('quit', 'v'),\n",
       " ('talking', 'v'),\n",
       " ('and', None),\n",
       " ('begin', 'v'),\n",
       " ('doing', 'v')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# лемматизация с учетом части речи\n",
    "# меняем теги\n",
    "def pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return nltk.corpus.wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return nltk.corpus.wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return nltk.corpus.wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return nltk.corpus.wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'way',\n",
       " 'to',\n",
       " 'get',\n",
       " 'start',\n",
       " 'be',\n",
       " 'to',\n",
       " 'quit',\n",
       " 'talk',\n",
       " 'and',\n",
       " 'begin',\n",
       " 'do']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# лемматизируем\n",
    "#tagged = [(word, pos_tagger(tag)) for word, tag in tagged]\n",
    "lemmatized = []\n",
    "for word, tag in tagged:\n",
    "    if tag == None:\n",
    "        lemmatized.append(lemm.lemmatize(word))\n",
    "    else:\n",
    "        lemmatized.append(lemm.lemmatize(word, tag))\n",
    "lemmatized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'way',\n",
       " 'to',\n",
       " 'get',\n",
       " 'start',\n",
       " 'is',\n",
       " 'to',\n",
       " 'quit',\n",
       " 'talk',\n",
       " 'and',\n",
       " 'begin',\n",
       " 'do']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Стемминг English\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "stemmed = [stemmer.stem(word) for word in tokenized]\n",
    "stemmed\n",
    "'The way to get started is to quit talking and begin doing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['у', 'лукомор', 'дуб', 'зелен', ',', 'злат', 'цеп', 'на', 'дуб', 'том']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Стемминг russian\n",
    "stemmer = SnowballStemmer(language='russian')\n",
    "text = 'У Лукоморья дуб зеленый, златая цепь на дубе том'\n",
    "tokenized = nltk.word_tokenize(text)\n",
    "stemmed = [stemmer.stem(word) for word in tokenized]\n",
    "stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pymorphy\n",
    "https://pymorphy2.readthedocs.io/en/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VERB'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "morph.parse('стали')[0].tag.POS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='варкалось', tag=OpencorporaTag('NOUN,anim,masc sing,nomn'), normal_form='варкалось', score=0.5000531180282588, methods_stack=((DictionaryAnalyzer(), 'лось', 123, 0), (UnknownPrefixAnalyzer(score_multiplier=0.5), 'варка'))),\n",
       " Parse(word='варкалось', tag=OpencorporaTag('VERB,impf,intr neut,sing,past,indc'), normal_form='варкаться', score=0.4999468819717412, methods_stack=((FakeDictionary(), 'варкалось', 234, 9), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), 'алось')))]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Варкалось'\n",
    "morph.parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
